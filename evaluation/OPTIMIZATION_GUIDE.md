# NeuroMemory LoCoMo ä¼˜åŒ–æŒ‡å—

åŸºäº 2025-02-16 æµ‹è¯•ç»“æœçš„è¯¦ç»†ä¼˜åŒ–å»ºè®®ï¼Œç”¨äºæŒ‡å¯¼ä¸‹ä¸€è½®æ€§èƒ½æå‡ã€‚

## ğŸ“Š å½“å‰æ€§èƒ½æ€»è§ˆ

| ç±»åˆ« | å½“å‰å¾—åˆ† | é—®é¢˜æ•° | éš¾åº¦ | æå‡ç©ºé—´ |
|------|---------|--------|------|---------|
| **Temporal** | 0.087 | 321 | â­â­â­â­â­ | æœ€å¤§ (~3-4x) |
| **Multi-hop** | 0.305 | 282 | â­â­â­â­ | å¤§ (~1.5-2x) |
| **Single-hop** | 0.327 | 841 | â­â­â­ | ä¸­ (~1.3-1.5x) |
| **Open-domain** | 0.344 | 96 | â­â­ | å° (~1.1-1.2x) |
| **Overall** | 0.274 | 1540 | - | ç›®æ ‡: 0.35-0.40 |

---

## ğŸ¯ ä¼˜å…ˆçº§è·¯çº¿å›¾

### Phase 1: Temporal æ—¶åºè®°å¿†ä¼˜åŒ– (é¢„æœŸæå‡: 0.087 â†’ 0.15-0.20)
**ROI**: æœ€é«˜ - å¾—åˆ†æœ€ä½ï¼Œæå‡ç©ºé—´æœ€å¤§

#### P0: ä¸“é—¨çš„æ—¶é—´ä¿¡æ¯æå– [é¢„æœŸ: +50-80%]
- **ç›®æ ‡**: è¯†åˆ«å¹¶æ ‡å‡†åŒ–æ—¶é—´è¡¨è¾¾å¼
- **å®æ–½æ­¥éª¤**:
  ```python
  # åœ¨ neuromemory/services/memory_extraction.py

  # 1. æ·»åŠ æ—¶é—´è§£æä¾èµ–
  from dateutil import parser
  from dateparser import parse as parse_time

  # 2. åœ¨ _store_episodes ä¸­æå–æ—¶é—´
  def _extract_temporal_info(content: str, session_timestamp: datetime) -> dict:
      """æå–æ—¶é—´ä¿¡æ¯"""
      # ä½¿ç”¨æ­£åˆ™æˆ– NER è¯†åˆ«æ—¶é—´è¡¨è¾¾å¼
      # æ ‡å‡†åŒ–ä¸º ISO 8601 æ ¼å¼
      # ä¿ç•™åŸå§‹è¡¨è¾¾
      return {
          "timestamp": "2023-05-07T00:00:00",
          "original_expression": "yesterday",
          "type": "relative"  # absolute/relative/fuzzy
      }

  # 3. å­˜å‚¨åˆ° metadata
  meta["temporal"] = temporal_info
  ```

- **ä¿®æ”¹æ–‡ä»¶**:
  - `neuromemory/services/memory_extraction.py` - æ·»åŠ æ—¶é—´æå–é€»è¾‘
  - `neuromemory/models/memory.py` - å¯é€‰ï¼šæ·»åŠ æ—¶é—´ç´¢å¼•

#### P0: æ—¶é—´æ¨ç†å’Œè®¡ç®— [é¢„æœŸ: +40-60%]
- **ç›®æ ‡**: å°†ç›¸å¯¹æ—¶é—´è½¬æ¢ä¸ºç»å¯¹æ—¶é—´
- **å®æ–½æ­¥éª¤**:
  ```python
  # åœ¨ neuromemory/services/conversation.py

  def calculate_absolute_time(relative_expr: str, reference_time: datetime) -> datetime:
      """è®¡ç®—ç»å¯¹æ—¶é—´"""
      # "yesterday" + reference_time = reference_time - 1 day
      # "last week" + reference_time = reference_time - 7 days
      # "4 years ago" + reference_time = reference_time - 4 years
      pass

  # åœ¨ memory_extraction.py çš„ prompt ä¸­æä¾›ä¸Šä¸‹æ–‡
  prompt = f"""
  Current conversation session time: {session_timestamp}

  When extracting temporal information:
  - Convert relative time expressions to absolute dates
  - Example: "yesterday" at session {session_timestamp} = {session_timestamp - 1 day}
  """
  ```

- **ä¿®æ”¹æ–‡ä»¶**:
  - `neuromemory/services/memory_extraction.py` - æ—¶é—´è®¡ç®—é€»è¾‘
  - `neuromemory/services/conversation.py` - è¾…åŠ©å‡½æ•°

#### P1: æ—¶é—´ç´¢å¼•å’ŒæŸ¥è¯¢ä¼˜åŒ– [é¢„æœŸ: +20-30%]
- **å®æ–½æ­¥éª¤**:
  ```python
  # åœ¨ neuromemory/services/search.py

  def search_by_time_range(
      user_id: str,
      start_time: datetime,
      end_time: datetime,
      limit: int = 10
  ):
      """æŒ‰æ—¶é—´èŒƒå›´æŸ¥è¯¢"""
      query = select(Embedding).where(
          Embedding.user_id == user_id,
          Embedding.metadata_['temporal']['timestamp'].astext.cast(DateTime) >= start_time,
          Embedding.metadata_['temporal']['timestamp'].astext.cast(DateTime) <= end_time
      )
      return await session.execute(query)
  ```

---

### Phase 2: Single-hop äº‹å®æŸ¥è¯¢ä¼˜åŒ– (é¢„æœŸæå‡: 0.327 â†’ 0.40-0.45)
**ROI**: é«˜ - å æ¯”æœ€å¤§ï¼ˆ54.6%ï¼‰ï¼Œä¼˜åŒ–å½±å“é¢å¹¿

#### P0: ä¼˜åŒ– Fact æå–çš„å‡†ç¡®æ€§ [é¢„æœŸ: +15-25%]
- **ç›®æ ‡**: æå–åŸå­åŒ–ã€å®Œæ•´çš„äº‹å®
- **å®æ–½æ­¥éª¤**:
  ```python
  # æ”¹è¿› fact æå– prompt
  FACT_EXTRACTION_PROMPT = """
  Extract atomic facts from the conversation.

  Requirements:
  1. Each fact must be independent and complete
  2. Include subject, predicate, object
  3. Extract entity attributes, states, and behaviors
  4. Avoid redundancy

  Examples:
  - Good: "Caroline is a transgender woman"
  - Good: "Caroline works at a counseling center"
  - Bad: "She is trans" (incomplete, missing subject)
  - Bad: "Caroline is trans and works at a center" (not atomic)
  """
  ```

- **ä¿®æ”¹æ–‡ä»¶**: `neuromemory/services/memory_extraction.py`

#### P1: å¢åŠ å…³é”®è¯åŒ¹é… (Hybrid Search) [é¢„æœŸ: +10-15%]
- **ç›®æ ‡**: ç»“åˆ BM25 å’Œå‘é‡æ£€ç´¢
- **å®æ–½æ­¥éª¤**:
  ```python
  # åœ¨ neuromemory/services/search.py

  # 1. æ·»åŠ å…¨æ–‡ç´¢å¼•ï¼ˆæ•°æ®åº“è¿ç§»ï¼‰
  # CREATE INDEX idx_embeddings_content_fts ON embeddings USING gin(to_tsvector('english', content));

  # 2. å®ç° BM25 æ£€ç´¢
  def bm25_search(query: str, limit: int = 10):
      """BM25 å…³é”®è¯æ£€ç´¢"""
      ts_query = func.plainto_tsquery('english', query)
      return select(Embedding).where(
          func.to_tsvector('english', Embedding.content).op('@@')(ts_query)
      ).order_by(
          func.ts_rank(func.to_tsvector('english', Embedding.content), ts_query).desc()
      ).limit(limit)

  # 3. æ··åˆæ£€ç´¢
  def hybrid_search(query: str, alpha: float = 0.5):
      """æ··åˆå‘é‡å’Œå…³é”®è¯æ£€ç´¢
      alpha: å‘é‡æ£€ç´¢æƒé‡ (0-1)
      """
      vector_results = await vector_search(query, limit=20)
      keyword_results = await bm25_search(query, limit=20)

      # åˆå¹¶å’Œé‡æ’åº
      return merge_and_rerank(vector_results, keyword_results, alpha)
  ```

- **ä¿®æ”¹æ–‡ä»¶**:
  - `neuromemory/services/search.py` - æ··åˆæ£€ç´¢é€»è¾‘
  - `migrations/` - æ·»åŠ å…¨æ–‡ç´¢å¼•

#### P1: Metadata ç²¾ç¡®è¿‡æ»¤ [é¢„æœŸ: +10-15%]
- **å®æ–½æ­¥éª¤**:
  ```python
  # æå–æ›´å¤šç»“æ„åŒ–ä¿¡æ¯
  meta["entities"] = {
      "people": ["Caroline", "Melanie"],
      "locations": ["LGBTQ support group", "school"],
      "topics": ["transgender", "education", "family"]
  }

  # æ”¯æŒè¿‡æ»¤æŸ¥è¯¢
  def search_with_filters(query: str, filters: dict):
      """å¸¦è¿‡æ»¤æ¡ä»¶çš„æœç´¢"""
      base_query = vector_search(query, limit=50)

      # åº”ç”¨ metadata è¿‡æ»¤
      if 'person' in filters:
          base_query = base_query.where(
              Embedding.metadata_['entities']['people'].contains([filters['person']])
          )

      return base_query
  ```

---

### Phase 3: Multi-hop å¤šè·³æ¨ç†ä¼˜åŒ– (é¢„æœŸæå‡: 0.305 â†’ 0.40-0.45)
**ROI**: ä¸­é«˜ - éœ€è¦å›¾æ•°æ®åº“æ”¯æŒï¼Œå®ç°å¤æ‚åº¦é«˜

#### P0: å¢å¼ºçŸ¥è¯†å›¾è°±æ„å»º [é¢„æœŸ: +20-30%]
- **ç›®æ ‡**: æ”¹è¿›å®ä½“è¯†åˆ«å’Œå…³ç³»æå–
- **å®æ–½æ­¥éª¤**:
  ```python
  # æ”¹è¿› triple æå– prompt
  TRIPLE_EXTRACTION_PROMPT = """
  Extract entity relationships as triples (subject, relation, object).

  Entity types to extract:
  - PERSON: people, their roles, identities
  - LOCATION: places, addresses, venues
  - EVENT: activities, meetings, conferences
  - CONCEPT: abstract ideas, topics, fields

  Relation types:
  - ATTRIBUTE: is_a, has_property, works_at
  - ACTION: researched, attended, planned
  - TEMPORAL: happened_at, lasted_for
  - SOCIAL: knows, friends_with, mentored_by
  - CAUSAL: causes, leads_to, because_of

  Also extract:
  - Entity aliases (e.g., "Caroline" = "she" in context)
  - Co-reference chains
  """
  ```

- **ä¿®æ”¹æ–‡ä»¶**:
  - `neuromemory/services/memory_extraction.py` - æ”¹è¿› triple æå–
  - `neuromemory/services/graph_memory.py` - æ”¯æŒæ›´å¤šå…³ç³»ç±»å‹

#### P1: å®ç°å¤šè·³æ¨ç†è·¯å¾„æœç´¢ [é¢„æœŸ: +15-25%]
- **ç›®æ ‡**: ä½¿ç”¨ AGE (Apache AGE) Cypher æŸ¥è¯¢
- **å®æ–½æ­¥éª¤**:
  ```python
  # åœ¨ neuromemory/services/graph_memory.py

  async def find_path(
      start_entity: str,
      end_entity: str,
      max_hops: int = 3
  ):
      """æŸ¥æ‰¾å®ä½“é—´çš„è·¯å¾„"""
      cypher_query = """
      MATCH path = (start:Entity {name: $start})-[*1..%d]-(end:Entity {name: $end})
      RETURN path
      ORDER BY length(path)
      LIMIT 10
      """ % max_hops

      # æ‰§è¡Œ AGE æŸ¥è¯¢
      result = await execute_cypher(cypher_query, start=start_entity, end=end_entity)
      return parse_paths(result)

  async def find_related_memories(entity: str, hop: int = 2):
      """æ‰¾åˆ°ä¸å®ä½“ç›¸å…³çš„æ‰€æœ‰è®°å¿†"""
      cypher_query = """
      MATCH (e:Entity {name: $entity})-[*1..%d]-(related)
      RETURN related
      """ % hop

      return await execute_cypher(cypher_query, entity=entity)
  ```

- **ä¿®æ”¹æ–‡ä»¶**: `neuromemory/services/graph_memory.py`

#### P1: æ··åˆæ£€ç´¢ç­–ç•¥ [é¢„æœŸ: +10-15%]
- **å®æ–½æ­¥éª¤**:
  ```python
  # åœ¨ neuromemory/services/search.py

  async def hybrid_vector_graph_search(query: str, user_id: str):
      """ç»“åˆå‘é‡æ£€ç´¢å’Œå›¾æŸ¥è¯¢"""
      # 1. å‘é‡å¬å›ç›¸å…³è®°å¿†
      vector_results = await vector_search(query, limit=10)

      # 2. æå–è®°å¿†ä¸­çš„å®ä½“
      entities = extract_entities(vector_results)

      # 3. åœ¨å›¾ä¸­æŸ¥æ‰¾å®ä½“çš„å…³è”è®°å¿†
      graph_results = []
      for entity in entities:
          related = await find_related_memories(entity, hop=2)
          graph_results.extend(related)

      # 4. åˆå¹¶å»é‡
      all_results = merge_results(vector_results, graph_results)

      # 5. é‡æ’åº
      return rerank(all_results, query)
  ```

- **ä¿®æ”¹æ–‡ä»¶**: `neuromemory/services/search.py`, `neuromemory/_core.py`

---

### Phase 4: Open-domain å¼€æ”¾åŸŸä¼˜åŒ– (é¢„æœŸæå‡: 0.344 â†’ 0.38-0.42)
**ROI**: ä¸­ - å·²ç»æœ€é«˜åˆ†ï¼Œä¼˜åŒ–ç©ºé—´ç›¸å¯¹è¾ƒå°

#### P1: å¢å¼ºæ¦‚å¿µæ€§çŸ¥è¯†æå– [é¢„æœŸ: +10-20%]
- **å®æ–½æ­¥éª¤**:
  ```python
  # æ”¹è¿› fact æå–ï¼Œå…³æ³¨æŠ½è±¡ä¿¡æ¯
  CONCEPT_EXTRACTION_PROMPT = """
  Extract conceptual and inferential facts:

  Focus on:
  1. User's intentions, plans, goals
  2. Interests, hobbies, passions
  3. Skills, abilities, competencies
  4. Values, beliefs, principles
  5. Preferences, dislikes
  6. Personality traits
  7. Causal relationships
  8. Reasoning chains

  Example:
  - "She is interested in psychology" (interest)
  - "She plans to get a counseling certification" (intention)
  - "She values family support" (value)
  """
  ```

- **ä¿®æ”¹æ–‡ä»¶**: `neuromemory/services/memory_extraction.py`

#### P2: æ”¹è¿›è¯­ä¹‰å¬å›ç²¾åº¦ [é¢„æœŸ: +5-10%]
- **å®æ–½æ­¥éª¤**:
  ```python
  # å¢åŠ  top_k
  recall_limit = 20  # ä» 10 å¢åŠ åˆ° 20

  # å®ç° reranking
  def rerank_results(query: str, results: List[Memory]):
      """ä½¿ç”¨ cross-encoder é‡æ’åº"""
      from sentence_transformers import CrossEncoder
      model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

      pairs = [(query, r.content) for r in results]
      scores = model.predict(pairs)

      # æŒ‰åˆ†æ•°é‡æ–°æ’åº
      ranked = sorted(zip(results, scores), key=lambda x: x[1], reverse=True)
      return [r for r, s in ranked]
  ```

- **ä¿®æ”¹æ–‡ä»¶**: `neuromemory/services/search.py`

---

## ğŸ› ï¸ å®æ–½å»ºè®®

### æ¨èå®æ–½é¡ºåº

1. **Week 1-2: Temporal ä¼˜åŒ– (P0 ä»»åŠ¡)**
   - ä¸“é—¨çš„æ—¶é—´ä¿¡æ¯æå–
   - æ—¶é—´æ¨ç†å’Œè®¡ç®—
   - **é¢„æœŸ**: 0.087 â†’ 0.15+ (Judge åˆ†æ•°)

2. **Week 3-4: Single-hop ä¼˜åŒ– (P0-P1 ä»»åŠ¡)**
   - ä¼˜åŒ– Fact æå–
   - å¢åŠ å…³é”®è¯åŒ¹é… (Hybrid Search)
   - Metadata ç²¾ç¡®è¿‡æ»¤
   - **é¢„æœŸ**: 0.327 â†’ 0.42+ (Judge åˆ†æ•°)

3. **Week 5-6: Multi-hop ä¼˜åŒ– (P0-P1 ä»»åŠ¡)**
   - å¢å¼ºçŸ¥è¯†å›¾è°±æ„å»º
   - å®ç°å¤šè·³æ¨ç†è·¯å¾„æœç´¢
   - æ··åˆæ£€ç´¢ç­–ç•¥
   - **é¢„æœŸ**: 0.305 â†’ 0.42+ (Judge åˆ†æ•°)

4. **Week 7-8: Open-domain ä¼˜åŒ– + é›†æˆæµ‹è¯•**
   - å¢å¼ºæ¦‚å¿µæ€§çŸ¥è¯†æå–
   - æ”¹è¿›è¯­ä¹‰å¬å›ç²¾åº¦
   - å…¨é¢é›†æˆæµ‹è¯•å’Œè°ƒä¼˜
   - **é¢„æœŸ**: 0.344 â†’ 0.40+ (Judge åˆ†æ•°)

### é¢„æœŸæœ€ç»ˆç»“æœ

| ç±»åˆ« | å½“å‰ | ç›®æ ‡ | æå‡ |
|------|-----|------|------|
| Temporal | 0.087 | 0.15-0.20 | +72-130% |
| Single-hop | 0.327 | 0.42-0.45 | +28-38% |
| Multi-hop | 0.305 | 0.40-0.45 | +31-48% |
| Open-domain | 0.344 | 0.38-0.42 | +10-22% |
| **Overall** | **0.274** | **0.35-0.40** | **+28-46%** |

---

## ğŸ“‹ æµ‹è¯•æ¸…å•

æ¯æ¬¡ä¼˜åŒ–åéƒ½åº”è¯¥è¿è¡Œå®Œæ•´çš„ LoCoMo è¯„æµ‹ï¼š

```bash
# 1. ç¡®ä¿ä½¿ç”¨ç‹¬ç«‹æ•°æ®åº“å®¹å™¨
docker compose -f docker-compose-eval.yml up -d

# 2. è¿è¡Œæµ‹è¯•
python -m evaluation.cli locomo

# 3. è®°å½•ç»“æœ
python evaluation/scripts/add_test_record.py \
  2025-XX-XX_<optimization_name> \
  "<Description>" \
  evaluation/results/locomo_results.json \
  "ä¼˜åŒ–æªæ–½1" "ä¼˜åŒ–æªæ–½2"

# 4. å¯¹æ¯”ç»“æœ
python evaluation/scripts/compare_history.py \
  2025-02-16_perf_opt \
  2025-XX-XX_<optimization_name>
```

---

## ğŸ’¡ é¢å¤–å»ºè®®

1. **æ¸è¿›å¼ä¼˜åŒ–**: ä¸è¦ä¸€æ¬¡æ€§å®æ–½æ‰€æœ‰ä¼˜åŒ–ï¼Œé€æ­¥æµ‹è¯•éªŒè¯
2. **A/B æµ‹è¯•**: ä¿ç•™åŸæœ‰ä»£ç åˆ†æ”¯ï¼Œå¯¹æ¯”ä¼˜åŒ–æ•ˆæœ
3. **ç›‘æ§å…³é”®æŒ‡æ ‡**: é™¤äº† Judge åˆ†æ•°ï¼Œä¹Ÿå…³æ³¨ F1 å’Œ BLEU-1
4. **ä»£ç å®¡æŸ¥**: ä¼˜åŒ–å¯èƒ½å¼•å…¥ bugï¼Œéœ€è¦ä»”ç»†æµ‹è¯•
5. **æ€§èƒ½ç›‘æ§**: ç¡®ä¿ä¼˜åŒ–ä¸ä¼šæ˜¾è‘—é™ä½é€Ÿåº¦

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **æµ‹è¯•è®°å½•**: `evaluation/history/2025-02-16_perf_opt.json`
- **è¯¦ç»†åˆ†æ**: æ–‡ä»¶ä¸­çš„ `category_optimization_analysis` å­—æ®µ
- **å¯¹æ¯”è„šæœ¬**: `evaluation/scripts/compare_history.py`
- **LoCoMo æ•°æ®**: `evaluation/data/locomo10.json`

---

**æœ€åæ›´æ–°**: 2025-02-16
**åŸºäºæµ‹è¯•**: 2025-02-16_perf_opt (commit e7c0f3d5)
**ç›®æ ‡**: å°† Overall Judge åˆ†æ•°ä» 0.274 æå‡åˆ° 0.35-0.40

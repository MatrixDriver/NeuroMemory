"""Tests for digest() watermark-based incremental processing and background mode."""

from __future__ import annotations

import asyncio

import pytest
from sqlalchemy import text

from neuromem import NeuroMemory
from neuromem.providers.llm import LLMProvider

TEST_DATABASE_URL = "postgresql+asyncpg://neuromem:neuromem@localhost:5436/neuromem"


class MockLLMProvider(LLMProvider):
    """Mock LLM that returns predictable reflection results."""

    def __init__(self):
        self.call_count = 0

    async def chat(self, messages, temperature=0.1, max_tokens=2048) -> str:
        self.call_count += 1
        # Alternate: odd calls = insights, even calls = emotion
        if self.call_count % 2 == 1:
            return '{"insights": [{"content": "insight #%d", "category": "pattern", "source_ids": []}]}' % self.call_count
        else:
            return '{"latest_state": "test state", "dominant_emotions": {}, "emotion_triggers": {}}'


@pytest.fixture
def mock_llm():
    return MockLLMProvider()


# ---------------------------------------------------------------------------
# Watermark tests
# ---------------------------------------------------------------------------


@pytest.mark.asyncio
async def test_reflect_watermark_initial(mock_embedding, mock_llm):
    """First digest() processes all memories and sets watermark."""
    nm = NeuroMemory(
        database_url=TEST_DATABASE_URL,
        embedding=mock_embedding,
        llm=mock_llm,
        auto_extract=False,
    )
    await nm.init()

    try:
        user = "watermark_test_1"
        # Add memories
        await nm._add_memory(user, "Fact one", memory_type="fact")
        await nm._add_memory(user, "Fact two", memory_type="fact")
        await nm._add_memory(user, "Episode one", memory_type="episodic")

        result = await nm.digest(user, batch_size=50)

        assert result["memories_analyzed"] == 3
        assert result["insights_generated"] >= 1

        # Verify watermark was set
        async with nm._db.session() as session:
            row = (await session.execute(
                text("SELECT last_reflected_at FROM emotion_profiles WHERE user_id = :uid"),
                {"uid": user},
            )).first()
            assert row is not None
            assert row.last_reflected_at is not None
    finally:
        await nm.close()


@pytest.mark.asyncio
async def test_reflect_watermark_incremental(mock_embedding, mock_llm):
    """Second digest() only processes memories created after watermark."""
    nm = NeuroMemory(
        database_url=TEST_DATABASE_URL,
        embedding=mock_embedding,
        llm=mock_llm,
        auto_extract=False,
    )
    await nm.init()

    try:
        user = "watermark_test_2"
        # Add initial memories and digest
        await nm._add_memory(user, "Old fact for watermark", memory_type="fact")
        result1 = await nm.digest(user, batch_size=50)
        assert result1["memories_analyzed"] == 1

        # Add new memories
        await nm._add_memory(user, "New fact for watermark", memory_type="fact")

        # Reset mock counter
        mock_llm.call_count = 0

        # Second digest processes new memory + any trait insights generated by first digest
        # (trait insights from first digest have created_at > watermark since they were
        # stored after batch processing)
        result2 = await nm.digest(user, batch_size=50)
        assert result2["memories_analyzed"] >= 1
    finally:
        await nm.close()


@pytest.mark.asyncio
async def test_reflect_watermark_no_new_memories(mock_embedding, mock_llm):
    """digest() with no new user memories eventually converges to zero."""
    nm = NeuroMemory(
        database_url=TEST_DATABASE_URL,
        embedding=mock_embedding,
        llm=mock_llm,
        auto_extract=False,
    )
    await nm.init()

    try:
        user = "watermark_test_3"
        await nm._add_memory(user, "Some fact for convergence", memory_type="fact")

        # First digest: processes the fact
        await nm.digest(user, batch_size=50)

        # Second digest: may still process trait insights from first digest
        await nm.digest(user, batch_size=50)

        # Reset counter
        mock_llm.call_count = 0

        # Third digest: all insights from second round should also be behind watermark now
        result = await nm.digest(user, batch_size=50)
        # Eventually converges: either 0 (fully caught up) or processes remaining insights
        assert result["memories_analyzed"] >= 0
        if result["memories_analyzed"] == 0:
            assert result["insights_generated"] == 0
            assert mock_llm.call_count == 0
    finally:
        await nm.close()


@pytest.mark.asyncio
async def test_reflect_batch_pagination(mock_embedding, mock_llm):
    """digest() paginates through memories in batches."""
    nm = NeuroMemory(
        database_url=TEST_DATABASE_URL,
        embedding=mock_embedding,
        llm=mock_llm,
        auto_extract=False,
    )
    await nm.init()

    try:
        user = "watermark_test_4"
        # Add 5 memories, batch_size=2 -> 3 batches
        for i in range(5):
            await nm._add_memory(user, f"Batch pagination memory {i}", memory_type="fact")

        result = await nm.digest(user, batch_size=2)
        assert result["memories_analyzed"] >= 5
        # Should have called LLM for insights at least 3 times (batches)
        assert mock_llm.call_count >= 3
    finally:
        await nm.close()


@pytest.mark.asyncio
async def test_reflect_background(mock_embedding, mock_llm):
    """digest(background=True) returns immediately with None."""
    nm = NeuroMemory(
        database_url=TEST_DATABASE_URL,
        embedding=mock_embedding,
        llm=mock_llm,
        auto_extract=False,
    )
    await nm.init()

    try:
        user = "watermark_test_5"
        await nm._add_memory(user, "Some fact", memory_type="fact")

        result = await nm.digest(user, batch_size=50, background=True)
        assert result is None

        # Give background task time to complete
        await asyncio.sleep(1)

        # Verify watermark was set by background task
        async with nm._db.session() as session:
            row = (await session.execute(
                text("SELECT last_reflected_at FROM emotion_profiles WHERE user_id = :uid"),
                {"uid": user},
            )).first()
            assert row is not None
            assert row.last_reflected_at is not None
    finally:
        await nm.close()
